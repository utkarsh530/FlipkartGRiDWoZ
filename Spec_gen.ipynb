{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import load\n",
    "from numpy import zeros\n",
    "from numpy import ones\n",
    "import numpy as np\n",
    "from numpy.random import randint\n",
    "from keras.optimizers import Adam\n",
    "from keras.initializers import RandomNormal\n",
    "from keras.models import Model\n",
    "from keras.models import Input\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import Conv2DTranspose\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Concatenate\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import LeakyReLU\n",
    "from matplotlib import pyplot\n",
    "import keras\n",
    "from keras.callbacks import EarlyStopping\n",
    "import tensorflow as tf\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "  raise SystemError('GPU device not found')\n",
    "print('Found GPU at: {}'.format(device_name))\n",
    " \n",
    "\n",
    "def define_encoder_block(layer_in, n_filters, batchnorm=True):\n",
    "    init = RandomNormal(stddev=0.02)\n",
    "    g = Conv2D(n_filters, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(layer_in)\n",
    "    if batchnorm:\n",
    "        g = BatchNormalization()(g, training=True)\n",
    "    g = LeakyReLU(alpha=0.2)(g)\n",
    "    return g\n",
    " \n",
    "\n",
    "def decoder_block(layer_in, skip_in, n_filters, dropout=True):\n",
    "    init = RandomNormal(stddev=0.02)\n",
    "    g = Conv2DTranspose(n_filters, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(layer_in)\n",
    "    g = BatchNormalization()(g, training=True)\n",
    "    if dropout:\n",
    "        g = Dropout(0.5)(g, training=True)\n",
    "    g = Concatenate()([g, skip_in])\n",
    "    g = Activation('relu')(g)\n",
    "    return g\n",
    " \n",
    "\n",
    "def define_generator(image_shape=(128,128,1)):\n",
    "    init = RandomNormal(stddev=0.02)\n",
    "    in_image = Input(shape=image_shape)\n",
    "    e1 = define_encoder_block(in_image, 64, batchnorm=False)\n",
    "    e2 = define_encoder_block(e1, 128)\n",
    "    e3 = define_encoder_block(e2, 256)\n",
    "    e4 = define_encoder_block(e3, 512)\n",
    "    e5 = define_encoder_block(e4, 512)\n",
    "    e6 = define_encoder_block(e5, 512)\n",
    "    b = Conv2D(128, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(e6)\n",
    "    b = Activation('relu')(b)\n",
    "    d2 = decoder_block(b, e6, 512)\n",
    "    d3 = decoder_block(d2, e5, 512)\n",
    "    d4 = decoder_block(d3, e4, 512, dropout=False)\n",
    "    d5 = decoder_block(d4, e3, 256, dropout=False)\n",
    "    d6 = decoder_block(d5, e2, 256, dropout=False)\n",
    "    d7 = decoder_block(d6, e1, 64, dropout=False)\n",
    "    g = Conv2DTranspose(1, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d7)\n",
    "    out_image = Activation('tanh')(g)\n",
    "    model = Model(in_image, out_image)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = define_generator()\n",
    "model.compile(optimizer = 'adam', loss = keras.losses.Huber(), metrics = ['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "np_combined = np.array(os.listdir(\"spectrogram_audio\"))\n",
    "np_speech = np.array(os.listdir(\"spectrogram_speech\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_x = []\n",
    "Train_y = []\n",
    "j = 0\n",
    "for s in np_combined:\n",
    "    Train_x.append((np.load(\"spectrogram_audio/\"+s)))\n",
    "    Train_y.append((np.load(\"spectrogram_speech/\"+s)))\n",
    "    print(j)\n",
    "    j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = np.array(Train_x).reshape([len(Train_x),128,128,1])/80\n",
    "train_y = np.array(Train_y).reshape([len(Train_y),128,128,1])/80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_x[:4500], train_y[:4500], validation_data=(train_x[4500:], train_y[4500:]), epochs=20,batch_size=32, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio,sr = librosa.load(\"combined_street/6.wav\",8000)\n",
    "n_fft = 255\n",
    "hop_length_fft = 63\n",
    "frame_length = 8064\n",
    "chunk_mag = []\n",
    "chunk_pha = []\n",
    "i = 0\n",
    "while (i+frame_length<len(audio)):\n",
    "    stftaudio = librosa.stft(audio[i:i+frame_length], n_fft=n_fft, hop_length=hop_length_fft)\n",
    "    stftaudio_magnitude, stftaudio_phase = librosa.magphase(stftaudio)\n",
    "\n",
    "    stftaudio_magnitude_db = librosa.amplitude_to_db(\n",
    "        stftaudio_magnitude, ref=np.max)\n",
    "    chunk_mag.append(stftaudio_magnitude_db/80)\n",
    "    chunk_pha.append(stftaudio_phase)\n",
    "    i += frame_length\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = np.array(chunk_mag).reshape([len(chunk_mag),128,128,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y = model.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(pred_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def magnitude_db_and_phase_to_audio(frame_length, hop_length_fft, stftaudio_magnitude_db, stftaudio_phase):\n",
    "\n",
    "    stftaudio_magnitude_rev = librosa.db_to_amplitude(stftaudio_magnitude_db, ref=1.0)\n",
    "\n",
    "    audio_reverse_stft = stftaudio_magnitude_rev * stftaudio_phase\n",
    "    audio_reconstruct = librosa.core.istft(audio_reverse_stft, hop_length=hop_length_fft, length=frame_length)\n",
    "\n",
    "    return audio_reconstruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrix_spectrogram_to_numpy_audio(m_mag_db, m_phase, frame_length, hop_length_fft)  :\n",
    "\n",
    "    list_audio = []\n",
    "\n",
    "    nb_spec = m_mag_db.shape[0]\n",
    "\n",
    "    for i in range(nb_spec):\n",
    "\n",
    "        audio_reconstruct = magnitude_db_and_phase_to_audio(frame_length, hop_length_fft, m_mag_db[i], m_phase[i])\n",
    "        list_audio.append(audio_reconstruct)\n",
    "\n",
    "    return np.vstack(list_audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_denoise_recons = matrix_spectrogram_to_numpy_audio(pred_y[:,:,:,0]*80, np.array(chunk_pha), frame_length, hop_length_fft)\n",
    "nb_samples = audio_denoise_recons.shape[0]\n",
    "denoise_long = audio_denoise_recons.reshape(1, nb_samples * frame_length)*10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(denoise_long[0, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio,sr = librosa.load(\"parallel_speech/6.wav\",8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython.display as ipd\n",
    "ipd.Audio(data = denoise_long[0, :], rate = sr )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(data = audio, rate = sr )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio,sr = librosa.load(\"combined_street/6.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(data = audio, rate = sr )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio,sr = librosa.load(\"combined_street/195.wav\", sr = 8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gputest",
   "language": "python",
   "name": "gputest"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
