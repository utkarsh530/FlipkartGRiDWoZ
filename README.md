# FlipkartGRiD 2.0 - Submission for Wheels of Zeus

## 1. Problem statement and Testing Dataset

[Round 3 Problem and Testing dataset](https://drive.google.com/file/d/1jqy-HowmuFyjAg4JJGNMoFHqkVBlwyl9/view?usp=sharing)


## 2. Dataset Links

### 2.1 Background Noise

- [UrbanSound8K](https://urbansounddataset.weebly.com/urbansound8k.html)
- [AudioSet Ontology by Freesound Datasets](https://annotator.freesound.org/fsd/)

### 2.2 Human Voice
- [AudioSet(Google)](https://research.google.com/audioset/)
- [Common Voice](https://voice.mozilla.org/en/datasets)
- [LibriSpeech](http://www.openslr.org/12/)

## 3. Research Papers and References

- [MMDenseLSTM: An efficient combination of convolutional and recurrent neural networks for audio source separation](https://arxiv.org/abs/1805.02410)
- [Unet Architecture](https://towardsdatascience.com/understanding-semantic-segmentation-with-unet-6be4f42d4b47)
- [Mel spectrogram using Librosa](https://towardsdatascience.com/getting-to-know-the-mel-spectrogram-31bca3e2d9d0)
- [Cocktail Party Source Separation using Deep Learning](https://www.mathworks.com/help/deeplearning/ug/cocktail-party-source-separation-using-deep-learning-networks.html)
- [Investigating Deep Neural Transformations for Spectrogram-based Musical Source Separation](https://arxiv.org/abs/1912.02591)
